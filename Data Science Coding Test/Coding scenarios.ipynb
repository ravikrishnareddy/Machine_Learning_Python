{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-143d4f5127b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m### Question 01\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mds_01\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"dataset_01.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Input:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'\\n'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mds_01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\n\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mds_01\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'any'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Company'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "### Question 01\n",
    "ds_01 = pd.read_csv(\"dataset_01.csv\")\n",
    "print(\"Input:\", '\\n', ds_01, end='\\n\\n')\n",
    "\n",
    "ds_01['Max_Sales'] = ds_01.iloc[:,[2, 3]].max(axis=1)\n",
    "print(\"Expected output:\", '\\n', ds_01)\n",
    "\n",
    "ds_01.to_csv('output_01.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      "        Date Company  Sales_1  Sales_2\n",
      "0  1/1/2020       A      250      300\n",
      "1  1/2/2020       A      150      100\n",
      "2  1/1/2020       B      350      270\n",
      "3  1/2/2020       B      500      600\n",
      "\n",
      "Expected output: \n",
      "   Company  Max_Sales\n",
      "0       A        300\n",
      "1       B        600\n"
     ]
    }
   ],
   "source": [
    "### Question 02\n",
    "ds_02 = pd.read_csv(\"dataset_02.csv\", sep='\\t')\n",
    "print(\"Input:\", '\\n', ds_02, end='\\n\\n')\n",
    "\n",
    "ds_02 = pd.DataFrame(ds_02.groupby('Company').max()[['Sales_1', 'Sales_2']].max(axis=1)).reset_index()\n",
    "ds_02.columns = ['Company', \"Max_Sales\"]\n",
    "print(\"Expected output:\", '\\n', ds_02)\n",
    "\n",
    "ds_02.to_csv('output_02.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      "                                          URL\n",
      "0           https://www.linkedin.com/prakash\n",
      "1          https://www.facebook.com/in/arjun\n",
      "2     https://www.myportal.in/home/asp/ahmed\n",
      "3  https://in.newportal.com/home/dep/d1/john\n",
      "\n",
      "Expected output: \n",
      "                                          URL Username\n",
      "0           https://www.linkedin.com/prakash  Prakash\n",
      "1          https://www.facebook.com/in/arjun    Arjun\n",
      "2     https://www.myportal.in/home/asp/ahmed    Ahmed\n",
      "3  https://in.newportal.com/home/dep/d1/john     John\n"
     ]
    }
   ],
   "source": [
    "### Question 03\n",
    "ds_03 = pd.read_csv(\"dataset_03.csv\", sep='\\t')\n",
    "print(\"Input:\", '\\n', ds_03, end='\\n\\n')\n",
    "\n",
    "ds_03['Username'] = ds_03['URL'].map(lambda x: x[::-1][0:x[::-1].index('/')][::-1].capitalize())\n",
    "print(\"Expected output:\", '\\n', ds_03)\n",
    "\n",
    "ds_03.to_csv('output_03.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      "   Representative    Country    Capital  Sales(B)\n",
      "0          Abdul      India  New Delhi        10\n",
      "1          Tania      India  New Delhi        10\n",
      "2          Abdul  Australia   Canberra         5\n",
      "3          Tania  Australia   Canberra         5\n",
      "4          Abdul      China    Beijing        15\n",
      "5          Abdul     Russia     Moscow         9\n",
      "\n",
      "Expected output: \n",
      "   Representative    Country    Capital  Sales(B)  Result\n",
      "1          Tania      India  New Delhi        10      50\n",
      "3          Tania  Australia   Canberra         5      45\n",
      "4          Abdul      China    Beijing        15      75\n",
      "5          Abdul     Russia     Moscow         9      54\n"
     ]
    }
   ],
   "source": [
    "### Question 04\n",
    "ds_04 = pd.read_csv(\"dataset_04.csv\")\n",
    "print(\"Input:\",'\\n',ds_04, end='\\n\\n')\n",
    "\n",
    "ds_04.drop_duplicates(subset=['Country', 'Capital'], keep='last', inplace = True)\n",
    "ds_04['Result'] = ds_04['Country'].apply(len) * ds_04['Sales(B)']\n",
    "print(\"Expected output:\", '\\n', ds_04)\n",
    "\n",
    "ds_04.to_csv('output_04.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      "   Start_Date   End_Date        SKU   Account\n",
      "0 2020-01-26 2020-02-01    OJ 5260    Amazon\n",
      "1 2020-01-20 2020-02-01  LJP M404n  Best Buy \n",
      "\n",
      "\n",
      "Expected output: \n",
      "   Start_Date   End_Date        SKU   Account  Days\n",
      "0 2020-01-26 2020-02-01    OJ 5260    Amazon     6\n",
      "1 2020-01-20 2020-02-01  LJP M404n  Best Buy    12\n"
     ]
    }
   ],
   "source": [
    "### Question 05\n",
    "ds_05 = pd.read_csv('dataset_05.csv', parse_dates=['Start_Date', 'End_Date'])\n",
    "print('Input:', '\\n', ds_05, '\\n\\n')\n",
    "\n",
    "ds_05['Days'] = (ds_05['End_Date'] - ds_05['Start_Date']).dt.days\n",
    "print(\"Expected output:\", '\\n', ds_05)\n",
    "\n",
    "ds_05.to_csv('output_05.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      "          SKU  Account  Sales\n",
      "0    OJ 5260   Amazon     10\n",
      "1  LJP M404n  Walmart     20 \n",
      "\n",
      "\n",
      "Expected Output: \n",
      "           SKU  Account Sales  Order_Date\n",
      "0     OJ 5260   Amazon    10  2020-01-26\n",
      "1     OJ 5260   Amazon    10  2020-01-27\n",
      "2     OJ 5260   Amazon    10  2020-01-28\n",
      "3     OJ 5260   Amazon    10  2020-01-29\n",
      "4     OJ 5260   Amazon    10  2020-01-30\n",
      "5     OJ 5260   Amazon    10  2020-01-31\n",
      "6     OJ 5260   Amazon    10  2020-02-01\n",
      "7   LJP M404n  Walmart    20  2020-01-26\n",
      "8   LJP M404n  Walmart    20  2020-01-27\n",
      "9   LJP M404n  Walmart    20  2020-01-28\n",
      "10  LJP M404n  Walmart    20  2020-01-29\n",
      "11  LJP M404n  Walmart    20  2020-01-30\n",
      "12  LJP M404n  Walmart    20  2020-01-31\n",
      "13  LJP M404n  Walmart    20  2020-02-01\n"
     ]
    }
   ],
   "source": [
    "### Question 06\n",
    "dates = ['2020-01-30', '2020-01-27', '2020-01-26', '2020-01-29', '2020-01-31', '2020-01-28', '2020-02-01']\n",
    "\n",
    "ds_06 = pd.read_csv('dataset_06.csv', sep='\\t')\n",
    "print('Input:', '\\n', ds_06, '\\n\\n')\n",
    "\n",
    "ds_06 = pd.DataFrame(ds_06.values.repeat(len(dates), axis = 0), columns=ds_06.columns)\n",
    "ds_06['Order_Date'] = dates * ds_06.drop_duplicates(keep = 'first').shape[0]\n",
    "ds_06.sort_values(by=['Account', 'SKU', 'Order_Date'], inplace = True)\n",
    "print('Expected Output:', '\\n', ds_06.reset_index(drop = True))\n",
    "\n",
    "ds_06.to_csv('output_06.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Output: \n",
      "   Country_Code         Country    Capital\n",
      "0          SIN       Singapore  Singapore\n",
      "1          IND           India  New Delhi\n",
      "2          CHN           China    Beijing\n",
      "3          JPN           Japan      Tokyo\n",
      "4          IRN            Iran     Tehran\n",
      "5          ITL           Italy       Rome\n",
      "6           UK  United Kingdom     London\n",
      "7          NTH     Netherlands  The Hague\n",
      "8          GER         Germany     Berlin\n",
      "9          FRA          France      Paris\n"
     ]
    }
   ],
   "source": [
    "### Question 07\n",
    "asia_countries = pd.read_excel('dataset_07.xlsx', sheet_name = 'Asia_Countries')\n",
    "asia_capitals = pd.read_excel('dataset_07.xlsx', sheet_name = 'Asia_Capitals')\n",
    "europe_countries = pd.read_excel('dataset_07.xlsx', sheet_name = 'Europe_Countries')\n",
    "europe_capitals = pd.read_excel('dataset_07.xlsx', sheet_name = 'Europe_Capitals')\n",
    "\n",
    "asia = pd.merge(asia_countries, asia_capitals)\n",
    "\n",
    "europe = pd.merge(europe_countries, europe_capitals)\n",
    "\n",
    "ds_07 = pd.concat([asia, europe]).reset_index(drop = True)\n",
    "\n",
    "print('Expected Output:', '\\n', ds_07)\n",
    "\n",
    "ds_07.to_csv('output_07.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      "         Date  Day  Cases_Guinea  Cases_Liberia  Cases_SierraLeone  \\\n",
      "0 2015-01-05  289        2776.0            NaN            10030.0   \n",
      "1 2015-01-04  288        2775.0            NaN             9780.0   \n",
      "2 2015-01-03  287        2769.0         8166.0             9722.0   \n",
      "3 2015-01-02  286           NaN         8157.0                NaN   \n",
      "4 2014-12-31  284        2730.0         8115.0             9633.0   \n",
      "\n",
      "   Cases_Nigeria  Cases_Senegal  Cases_UnitedStates  Cases_Spain  Cases_Mali  \\\n",
      "0            NaN            NaN                 NaN          NaN         NaN   \n",
      "1            NaN            NaN                 NaN          NaN         NaN   \n",
      "2            NaN            NaN                 NaN          NaN         NaN   \n",
      "3            NaN            NaN                 NaN          NaN         NaN   \n",
      "4            NaN            NaN                 NaN          NaN         NaN   \n",
      "\n",
      "   Deaths_Guinea  Deaths_Liberia  Deaths_SierraLeone  Deaths_Nigeria  \\\n",
      "0         1786.0             NaN              2977.0             NaN   \n",
      "1         1781.0             NaN              2943.0             NaN   \n",
      "2         1767.0          3496.0              2915.0             NaN   \n",
      "3            NaN          3496.0                 NaN             NaN   \n",
      "4         1739.0          3471.0              2827.0             NaN   \n",
      "\n",
      "   Deaths_Senegal  Deaths_UnitedStates  Deaths_Spain  Deaths_Mali  \n",
      "0             NaN                  NaN           NaN          NaN  \n",
      "1             NaN                  NaN           NaN          NaN  \n",
      "2             NaN                  NaN           NaN          NaN  \n",
      "3             NaN                  NaN           NaN          NaN  \n",
      "4             NaN                  NaN           NaN          NaN   \n",
      "\n",
      "\n",
      "Expected Output: \n",
      "          Country Cases_Deaths  Cases_Deaths_Count\n",
      "0         Guinea        Cases             84729.0\n",
      "1         Guinea       Deaths             51818.0\n",
      "2        Liberia        Cases            193833.0\n",
      "3        Liberia       Deaths             89198.0\n",
      "4           Mali        Cases                42.0\n",
      "5           Mali       Deaths                38.0\n",
      "6        Nigeria        Cases               636.0\n",
      "7        Nigeria       Deaths               233.0\n",
      "8        Senegal        Cases                27.0\n",
      "9        Senegal       Deaths                 0.0\n",
      "10   SierraLeone        Cases            211181.0\n",
      "11   SierraLeone       Deaths             60352.0\n",
      "12         Spain        Cases                16.0\n",
      "13         Spain       Deaths                 3.0\n",
      "14  UnitedStates        Cases                59.0\n",
      "15  UnitedStates       Deaths                15.0\n"
     ]
    }
   ],
   "source": [
    "### Question 08\n",
    "ds_08 = pd.read_csv('dataset_08.csv', parse_dates=['Date'])\n",
    "print('Input:','\\n', ds_08.head(), '\\n\\n')\n",
    "\n",
    "ds_08 = pd.melt(ds_08, id_vars = ['Date', 'Day'], var_name='Cases_Deaths', value_name='Cases_Deaths_Count')\n",
    "ds_08['Country'] = ds_08['Cases_Deaths'].str.split(\"_\").map(lambda x:x[1])\n",
    "ds_08['Cases_Deaths'] = ds_08['Cases_Deaths'].str.split(\"_\").map(lambda x:x[0])\n",
    "ds_08 = ds_08.groupby(['Country', 'Cases_Deaths'])['Cases_Deaths_Count'].sum()\n",
    "ds_08 = ds_08.reset_index()\n",
    "print('Expected Output:', '\\n', ds_08)\n",
    "\n",
    "ds_08.to_csv('output_08.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      "   Country Continent Cases_Deaths  Cases_Deaths_Count\n",
      "0  Guinea    Africa        Cases              2776.0\n",
      "1  Guinea    Africa        Cases              2775.0\n",
      "2  Guinea    Africa        Cases              2769.0\n",
      "3  Guinea    Africa        Cases                 NaN\n",
      "4  Guinea    Africa        Cases              2730.0 \n",
      "\n",
      "\n",
      "Expected Output 1: \n",
      "         Country Continent     Cases   Deaths\n",
      "0        Guinea    Africa   84729.0  51818.0\n",
      "1       Liberia    Africa  193833.0  89198.0\n",
      "2          Mali    Africa      42.0     38.0\n",
      "3       Nigeria    Africa     636.0    233.0\n",
      "4       Senegal    Africa      27.0      0.0\n",
      "5   SierraLeone    Africa  211181.0  60352.0\n",
      "6         Spain    Europe      16.0      3.0\n",
      "7  UnitedStates        US      59.0     15.0 \n",
      "\n",
      "\n",
      "Expected Output 2: \n",
      "               Cases   Deaths\n",
      "Continent                   \n",
      "Africa     490448.0  33606.5\n",
      "Europe         16.0      3.0\n",
      "US             59.0     15.0\n"
     ]
    }
   ],
   "source": [
    "### Question 09\n",
    "ds_09 = pd.read_csv('dataset_09.csv')\n",
    "print('Input:', '\\n', ds_09.head(), '\\n\\n')\n",
    "\n",
    "ds_09 = pd.pivot_table(ds_09, index=['Country', 'Continent'], columns='Cases_Deaths', values='Cases_Deaths_Count', aggfunc=sum)\n",
    "ds_09 = ds_09.reset_index()\n",
    "ds_09.columns.name = ''\n",
    "print('Expected Output 1:', '\\n', ds_09, '\\n\\n')\n",
    "\n",
    "ds_09 = ds_09.groupby('Continent')['Cases', 'Deaths'].agg({'Cases':'sum', 'Deaths':'mean'})\n",
    "print('Expected Output 2:', '\\n', ds_09)\n",
    "\n",
    "ds_09.to_csv('output_09.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      "         City  Day  Bread  Butter\n",
      "0  Hyderabad    1     15       5\n",
      "1  Hyderabad    2     15       6\n",
      "2  Hyderabad    3     18       6\n",
      "3  Hyderabad    4     20       7\n",
      "4  Hyderabad    5     10       5 \n",
      "\n",
      "\n",
      "Expected Output: \n",
      "          Day  Bread  Butter\n",
      "0     Friday      6       5\n",
      "1     Monday      8       5\n",
      "2   Saturday     11       4\n",
      "3     Sunday     10       6\n",
      "4   Thursday     10       5\n",
      "5    Tuesday      8       5\n",
      "6  Wednesday      9       5\n"
     ]
    }
   ],
   "source": [
    "### Question 10\n",
    "ds_10 = pd.read_csv('dataset_10.csv')\n",
    "print('Input:', '\\n', ds_10.head(), '\\n\\n')\n",
    "\n",
    "ds_10['Day'].replace({0:'Sunday', 1:'Monday', 2:'Tuesday', 3:'Wednesday', 4:'Thursday', 5:'Friday', 6:'Saturday'}, inplace=True)\n",
    "ds_10 = ds_10.groupby('Day')[['Bread', 'Butter']].agg(lambda x:x.max()-x.min())\n",
    "ds_10.reset_index(inplace = True)\n",
    "print('Expected Output:', '\\n', ds_10)\n",
    "\n",
    "ds_10.to_csv('output_10.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      "         Team  Player  Runs  Wickets\n",
      "0      India   Rohit    50      2.0\n",
      "1      India   Kohli    50      NaN\n",
      "2      India  Sachin    70      4.0\n",
      "3  Australia  Warner    40      3.0\n",
      "4  Australia   Smith    60      5.0\n",
      "5  Australia  Heyden    50      NaN \n",
      "\n",
      "\n",
      "Expected Output: \n",
      "         Team  Player  Runs  Wickets    Points\n",
      "0      India   Rohit    50      2.0  0.104167\n",
      "1      India   Kohli    50      2.0  0.104167\n",
      "2      India  Sachin    70      4.0  0.145833\n",
      "3  Australia  Warner    40      3.0  0.070175\n",
      "4  Australia   Smith    60      5.0  0.105263\n",
      "5  Australia  Heyden    50      3.0  0.087719 \n",
      "\n",
      "\n",
      "Man of the match:  Sachin\n"
     ]
    }
   ],
   "source": [
    "### Question 11\n",
    "ds_11 = pd.read_csv('dataset_11.csv')\n",
    "print('Input:', '\\n', ds_11, '\\n\\n')\n",
    "\n",
    "#Impute NaN with minimum wickets of the team\n",
    "ds_11['Wickets'].fillna(ds_11.groupby('Team')['Wickets'].transform(min), inplace = True)\n",
    "\n",
    "#For each player, calculate the points\n",
    "#Points = Runs / ( sum(Runs * Wickets) group by country )\n",
    "ds_11['Points'] = ds_11.groupby('Team', group_keys=False).apply(lambda g:g.Runs/(g.Runs*g.Wickets).sum())\n",
    "print('Expected Output:', '\\n', ds_11, '\\n\\n')\n",
    "ds_11.to_csv('output_11.csv', index = False)\n",
    "\n",
    "#Print Player with highest points\n",
    "print(\"Man of the match: \", ds_11['Player'][ds_11['Points'].idxmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
